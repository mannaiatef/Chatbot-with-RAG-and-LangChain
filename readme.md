# Chatbot with RAG and LangChain

Un chatbot intelligent alimentÃ© par **Retrieval-Augmented Generation (RAG)** et **LangChain**, capable de rÃ©pondre Ã  des questions basÃ©es sur des documents PDF personnalisÃ©s.

## ğŸ¯ CaractÃ©ristiques

- **RAG (Retrieval-Augmented Generation)** : Combine recherche de documents et gÃ©nÃ©ration de rÃ©ponses
- **LangChain** : Framework puissant pour construire des applications LLM
- **Chroma Vector Database** : Stockage et recherche efficace d'embeddings
- **OpenAI API** : ModÃ¨les de langage avancÃ©s (GPT-4o-mini, text-embedding-3-large)
- **Interface Gradio** : Interface web intuitive et conviviale
- **Support PDF** : Charge et traite automatiquement les fichiers PDF

## ğŸ“‹ PrÃ©requis

- **Python 3.10+** (recommandÃ© 3.11+)
- **OpenAI API Key** - Obtenez une clÃ© sur [platform.openai.com](https://platform.openai.com/api-keys)
- **Git** (pour cloner le repository)

## ğŸš€ Guide d'Installation

### 1. Cloner le repository

```bash
git clone https://github.com/mannaiatef/Chatbot-with-RAG-and-LangChain.git
cd Chatbot-with-RAG-and-LangChain
```

### 2. CrÃ©er un environnement virtuel

**Sur Windows :**
```bash
python -m venv venv
venv\Scripts\Activate
```

**Sur macOS/Linux :**
```bash
python3 -m venv venv
source venv/bin/activate
```

### 3. Installer les dÃ©pendances

```bash
pip install -r requirements.txt
```

### 4. Configurer les variables d'environnement

CrÃ©ez un fichier `.env` Ã  la racine du projet :

```bash
# Copier le fichier d'exemple si disponible
cp .env.example .env

# Ou crÃ©er manuellement
echo "OPENAI_API_KEY=your-api-key-here" > .env
```

**âš ï¸ Important** : Remplacez `your-api-key-here` par votre clÃ© OpenAI rÃ©elle.

Vous pouvez obtenir votre clÃ© OpenAI ici : https://platform.openai.com/api-keys

## ğŸ“š Guide d'Utilisation

### PrÃ©paration des donnÃ©es

1. **CrÃ©ez un dossier `data`** Ã  la racine du projet s'il n'existe pas :
   ```bash
   mkdir data
   ```

2. **Ajoutez vos fichiers PDF** dans le dossier `data` :
   ```
   data/
   â”œâ”€â”€ document1.pdf
   â”œâ”€â”€ document2.pdf
   â””â”€â”€ ...
   ```

### Ã‰tape 1 : Ingestion des donnÃ©es

Avant de lancer le chatbot, ingÃ©rez vos documents PDF dans la base de donnÃ©es vectorielle :

```bash
python ingest_database.py
```

**Qu'est-ce que cela fait ?**
- Charge tous les fichiers PDF du dossier `data`
- Divise les documents en chunks optimisÃ©s
- CrÃ©e des embeddings avec le modÃ¨le OpenAI
- Stocke les embeddings dans Chroma DB

### Ã‰tape 2 : Lancer le chatbot

Une fois l'ingestion terminÃ©e, dÃ©marrez l'interface web :

```bash
python chatbot.py
```

**AccÃ©dez Ã  l'interface :**
- L'application ouvrira automatiquement sur `http://127.0.0.1:7860`
- Ou accÃ©dez manuellement Ã  cette URL dans votre navigateur

### Utilisation du chatbot

1. **Posez des questions** relatives Ã  vos documents PDF
2. **Le chatbot rÃ©cupÃ¨re** les passages pertinents de votre base de donnÃ©es
3. **Les rÃ©ponses** sont basÃ©es uniquement sur vos documents (RAG)

**Exemple :**
- Documents contient : "La photosynthÃ¨se est le processus par lequel..."
- Question : "Qu'est-ce que la photosynthÃ¨se ?"
- RÃ©ponse : BasÃ©e sur le contenu de vos documents

## ğŸ“ Structure du Projet

```
Chatbot-with-RAG-and-LangChain/
â”œâ”€â”€ chatbot.py                 # Application chatbot (interface Gradio)
â”œâ”€â”€ ingest_database.py         # Script d'ingestion des documents
â”œâ”€â”€ requirements.txt           # DÃ©pendances Python
â”œâ”€â”€ .env                       # Variables d'environnement (non committÃ©e)
â”œâ”€â”€ .env.example               # Template pour .env
â”œâ”€â”€ .gitignore                 # Fichiers Ã  ignorer par Git
â”œâ”€â”€ data/                      # Dossier pour vos documents PDF
â”‚   â””â”€â”€ (vos fichiers PDF)
â”œâ”€â”€ chroma_db/                 # Base de donnÃ©es vectorielle
â”‚   â””â”€â”€ chroma.sqlite3
â””â”€â”€ README.md                  # Ce fichier
```

## ğŸ”§ Configuration AvancÃ©e

### Modifier les paramÃ¨tres

Dans `chatbot.py`, vous pouvez ajuster :

```python
# ModÃ¨le d'embeddings
embeddings_model = OpenAIEmbeddings(model="text-embedding-3-large")

# ModÃ¨le de langage
llm = ChatOpenAI(temperature=0.5, model='gpt-4o-mini')

# Nombre de rÃ©sultats de recherche
num_results = 5
```

Dans `ingest_database.py`, vous pouvez modifier :

```python
# Taille des chunks de texte
chunk_size=300,
# Chevauchement entre chunks
chunk_overlap=100,
```

## ğŸ› DÃ©pannage

### Erreur : "OPENAI_API_KEY environment variable is not set"

**Solution :**
1. VÃ©rifiez que votre fichier `.env` existe Ã  la racine du projet
2. VÃ©rifiez qu'il contient `OPENAI_API_KEY=votre_clÃ©`
3. Assurez-vous que votre clÃ© est valide sur https://platform.openai.com

### Erreur : "Error code: 429 - insufficient_quota"

**Solution :**
1. Votre quota OpenAI est Ã©puisÃ©
2. Ajoutez un moyen de paiement : https://platform.openai.com/account/billing/overview
3. VÃ©rifiez votre plan de facturation

### Erreur : "No documents found in data folder"

**Solution :**
1. CrÃ©ez le dossier `data` s'il n'existe pas
2. Ajoutez des fichiers PDF au dossier
3. Assurez-vous que les fichiers sont en format `.pdf`

### Le chatbot n'a pas accÃ¨s Ã  mes documents

**Solution :**
1. VÃ©rifiez que vous avez exÃ©cutÃ© `ingest_database.py` avant de lancer `chatbot.py`
2. Supprimez le dossier `chroma_db` et rÃ©exÃ©cutez l'ingestion si les documents ont changÃ©
3. VÃ©rifiez les logs pour les erreurs d'ingestion

## ğŸ“Š Flux de travail du RAG

```
PDF Documents
     â†“
PyPDFDirectoryLoader (Chargement)
     â†“
RecursiveCharacterTextSplitter (Division en chunks)
     â†“
OpenAI Embeddings (Conversion en vecteurs)
     â†“
Chroma Vector Store (Stockage)
     â†“
[Lors d'une question utilisateur]
     â†“
Similarity Search (Recherche des chunks pertinents)
     â†“
LLM Prompt Engineering (Construction du contexte)
     â†“
ChatOpenAI (GÃ©nÃ©ration de rÃ©ponse)
     â†“
Gradio UI (Affichage au utilisateur)
```

## ğŸ” SÃ©curitÃ©

- **Ne committez jamais votre fichier `.env`** avec votre clÃ© API
- Utilisez un `.gitignore` pour exclure `.env`
- Utilisez des secrets ou variables d'environnement en production
- Limitez vos clÃ©s API aux permissions minimales nÃ©cessaires

## ğŸ› ï¸ Technologies UtilisÃ©es

| Technologie | Version | Utilisation |
|-------------|---------|-------------|
| LangChain | 0.3.23 | Framework RAG et gestion LLM |
| OpenAI API | 1.74.0 | ModÃ¨les de langage et embeddings |
| Chroma | 0.6.3 | Base de donnÃ©es vectorielle |
| Gradio | 5.25.1 | Interface web |
| LangChain Chroma | 0.2.3 | IntÃ©gration Chroma |
| PyPDF | 5.4.0 | Traitement de fichiers PDF |
| Python Dotenv | 1.1.0 | Gestion variables d'environnement |

## ğŸ“ AmÃ©liorations Futures

- [ ] Support de multiples formats (DOCX, TXT, etc.)
- [ ] Historique conversationnel persistant
- [ ] Interface d'upload de fichiers
- [ ] Filtrage par mÃ©tadonnÃ©es
- [ ] ModÃ¨les locaux alternatifs
- [ ] Mode batch pour traitement multiple
- [ ] API REST pour intÃ©grations externes

## ğŸ¤ Contribution

Les contributions sont bienvenues ! N'hÃ©sitez pas Ã  :
- Signaler des bugs
- Proposer des amÃ©liorations
- Soumettre des pull requests

## ğŸ“„ Licence

Voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

## ğŸ“§ Support

Pour toute question ou problÃ¨me :
1. Consultez la section [DÃ©pannage](#-dÃ©pannage)
2. VÃ©rifiez les issues GitHub existantes
3. CrÃ©ez une nouvelle issue si besoin

## ğŸ“ Ressources Utiles

- [Documentation LangChain](https://python.langchain.com/)
- [Documentation OpenAI](https://platform.openai.com/docs/)
- [Documentation Chroma](https://docs.trychroma.com/)
- [Documentation Gradio](https://www.gradio.app/docs/)
- [RAG - Retrieval-Augmented Generation](https://arxiv.org/abs/2005.11401)

---

**CrÃ©Ã© avec â¤ï¸ pour faciliter l'interaction avec vos documents**

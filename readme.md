# Chatbot with RAG and LangChain

Un chatbot intelligent alimentÃ© par **Retrieval-Augmented Generation (RAG)** et **LangChain**, capable de rÃ©pondre Ã  des questions basÃ©es sur des documents PDF personnalisÃ©s. ğŸš€ **100% LOCAL** avec Ollama et Mistral !

## ğŸ¯ CaractÃ©ristiques

- **RAG (Retrieval-Augmented Generation)** : Combine recherche de documents et gÃ©nÃ©ration de rÃ©ponses
- **LangChain** : Framework puissant pour construire des applications LLM
- **Chroma Vector Database** : Stockage et recherche efficace d'embeddings
- **Ollama + Mistral** : LLM local gratuit, sans API (100% privÃ©) ğŸ”’
- **HuggingFace Embeddings** : Embeddings locaux gratuits (sentence-transformers) ğŸ’°
- **Interface Gradio** : Interface web intuitive et conviviale
- **Support PDF** : Charge et traite automatiquement les fichiers PDF
- **Sans coÃ»ts** : Aucune clÃ© API requise, tout s'exÃ©cute localement

## ğŸ“‹ PrÃ©requis

- **Python 3.10+** (recommandÃ© 3.11+)
- **Ollama** - TÃ©lÃ©chargez depuis [ollama.ai](https://ollama.ai)
- **Git** (pour cloner le repository)

### Installation d'Ollama

1. **TÃ©lÃ©chargez Ollama** : https://ollama.ai
2. **Installez-le** selon votre OS
3. **TÃ©lÃ©chargez le modÃ¨le Mistral** :
   ```bash
   ollama pull mistral
   ```
4. **VÃ©rifiez l'installation** :
   ```bash
   ollama list
   ```

## ğŸš€ Guide d'Installation

### 1. Cloner le repository

```bash
git clone https://github.com/mannaiatef/Chatbot-with-RAG-and-LangChain.git
cd Chatbot-with-RAG-and-LangChain
```

### 2. CrÃ©er un environnement virtuel

**Sur Windows :**
```bash
python -m venv venv
venv\Scripts\Activate
```

**Sur macOS/Linux :**
```bash
python3 -m venv venv
source venv/bin/activate
```

### 3. Installer les dÃ©pendances

```bash
pip install -r requirements.txt
```

### 4. Configuration (Optionnelle)

**Aucune clÃ© API requise !** Tout s'exÃ©cute localement.

âš ï¸ **Important** : Assurez-vous qu'Ollama est en cours d'exÃ©cution avant de lancer le chatbot :
```bash
# Sur Windows/macOS/Linux, vÃ©rifiez qu'Ollama s'exÃ©cute sur le port 11434
curl http://localhost:11434
```

## ğŸ“š Guide d'Utilisation

### PrÃ©paration des donnÃ©es

1. **CrÃ©ez un dossier `data`** Ã  la racine du projet s'il n'existe pas :
   ```bash
   mkdir data
   ```

2. **Ajoutez vos fichiers PDF** dans le dossier `data` :
   ```
   data/
   â”œâ”€â”€ document1.pdf
   â”œâ”€â”€ document2.pdf
   â””â”€â”€ ...
   ```

### Ã‰tape 1 : Ingestion des donnÃ©es

Avant de lancer le chatbot, ingÃ©rez vos documents PDF dans la base de donnÃ©es vectorielle :

```bash
python ingest_database.py
```

**Qu'est-ce que cela fait ?**
- Charge tous les fichiers PDF du dossier `data`
- Divise les documents en chunks optimisÃ©s
- CrÃ©e des embeddings locaux avec HuggingFace (sentence-transformers)
- Stocke les embeddings dans Chroma DB

### Ã‰tape 2 : Lancer le chatbot

Une fois l'ingestion terminÃ©e, dÃ©marrez l'interface web :

```bash
python chatbot.py
```

**AccÃ©dez Ã  l'interface :**
- L'application ouvrira automatiquement sur `http://127.0.0.1:7860`
- Ou accÃ©dez manuellement Ã  cette URL dans votre navigateur

### Utilisation du chatbot

1. **Posez des questions** relatives Ã  vos documents PDF
2. **Le chatbot rÃ©cupÃ¨re** les passages pertinents de votre base de donnÃ©es
3. **Les rÃ©ponses** sont basÃ©es uniquement sur vos documents (RAG)

**Exemple :**
- Documents contient : "La photosynthÃ¨se est le processus par lequel..."
- Question : "Qu'est-ce que la photosynthÃ¨se ?"
- RÃ©ponse : BasÃ©e sur le contenu de vos documents

## ğŸ“ Structure du Projet

```
Chatbot-with-RAG-and-LangChain/
â”œâ”€â”€ chatbot.py                 # Application chatbot (interface Gradio)
â”œâ”€â”€ ingest_database.py         # Script d'ingestion des documents
â”œâ”€â”€ requirements.txt           # DÃ©pendances Python
â”œâ”€â”€ .env                       # Variables d'environnement (non committÃ©e)
â”œâ”€â”€ .env.example               # Template pour .env
â”œâ”€â”€ .gitignore                 # Fichiers Ã  ignorer par Git
â”œâ”€â”€ data/                      # Dossier pour vos documents PDF
â”‚   â””â”€â”€ (vos fichiers PDF)
â”œâ”€â”€ chroma_db/                 # Base de donnÃ©es vectorielle
â”‚   â””â”€â”€ chroma.sqlite3
â””â”€â”€ README.md                  # Ce fichier
```

## ğŸ”§ Configuration AvancÃ©e

### Modifier les paramÃ¨tres

Dans `chatbot.py`, vous pouvez ajuster :

```python
# ModÃ¨le d'embeddings local (GRATUIT)
embeddings_model = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

# ModÃ¨le de langage local (Ollama + Mistral)
llm = Ollama(model="mistral", temperature=0.5)

# Nombre de rÃ©sultats de recherche
num_results = 5
```

Dans `ingest_database.py`, vous pouvez modifier :

```python
# Taille des chunks de texte
chunk_size=300,
# Chevauchement entre chunks
chunk_overlap=100,
```

## ğŸ› DÃ©pannage

### Erreur : "Connection refused" ou "Failed to connect to Ollama"

**Solution :**
1. VÃ©rifiez qu'Ollama est installÃ© depuis [ollama.ai](https://ollama.ai)
2. Lancez Ollama (il devrait s'exÃ©cuter en arriÃ¨re-plan)
3. VÃ©rifiez qu'il est accessible : `curl http://localhost:11434`
4. Assurez-vous que le modÃ¨le Mistral est tÃ©lÃ©chargÃ© : `ollama pull mistral`

### Erreur : "Model 'mistral' not found"

**Solution :**
```bash
# TÃ©lÃ©chargez le modÃ¨le Mistral
ollama pull mistral

# VÃ©rifiez qu'il est disponible
ollama list
```

### Erreur : "No documents found in data folder"

**Solution :**
1. CrÃ©ez le dossier `data` s'il n'existe pas
2. Ajoutez des fichiers PDF au dossier
3. Assurez-vous que les fichiers sont en format `.pdf`

### Le chatbot n'a pas accÃ¨s Ã  mes documents

**Solution :**
1. VÃ©rifiez que vous avez exÃ©cutÃ© `ingest_database.py` avant de lancer `chatbot.py`
2. Supprimez le dossier `chroma_db` et rÃ©exÃ©cutez l'ingestion si les documents ont changÃ©
3. VÃ©rifiez les logs pour les erreurs d'ingestion

### Performance lente du chatbot

**Solutions :**
1. Assurez-vous qu'Ollama a suffisamment de mÃ©moire RAM
2. RÃ©duisez la taille des chunks dans `ingest_database.py`
3. Diminuez le nombre de rÃ©sultats de recherche (`num_results`)

## ğŸ“Š Flux de travail du RAG

```
PDF Documents
     â†“
PyPDFDirectoryLoader (Chargement)
     â†“
RecursiveCharacterTextSplitter (Division en chunks)
     â†“
HuggingFace Embeddings (Conversion en vecteurs) âœ… LOCAL & GRATUIT
     â†“
Chroma Vector Store (Stockage)
     â†“
[Lors d'une question utilisateur]
     â†“
Similarity Search (Recherche des chunks pertinents)
     â†“
LLM Prompt Engineering (Construction du contexte)
     â†“
Ollama + Mistral (GÃ©nÃ©ration de rÃ©ponse) âœ… LOCAL & GRATUIT
     â†“
Gradio UI (Affichage au utilisateur)
```

## ğŸ” SÃ©curitÃ©

- âœ… **100% LOCAL** : Aucune donnÃ©e n'est envoyÃ©e Ã  des serveurs externes
- âœ… **Pas de clÃ© API** : Aucune exposition de credentials
- âœ… **DonnÃ©es privÃ©es** : Tout reste sur votre ordinateur
- Utilisez un `.gitignore` pour exclure les dossiers sensibles
- Limitez l'accÃ¨s au dossier `chroma_db` contenant les embeddings

## ğŸ› ï¸ Technologies UtilisÃ©es

| Technologie | Version | Utilisation | CoÃ»t |
|-------------|---------|-------------|------|
| LangChain | 0.3.23 | Framework RAG et gestion LLM | Gratuit |
| Ollama | Latest | ExÃ©cution locale de Mistral | Gratuit |
| Mistral | 7B | ModÃ¨le LLM local | Gratuit |
| HuggingFace Embeddings | 3.0.1 | Embeddings locaux | Gratuit ğŸ’° |
| Chroma | 0.6.3 | Base de donnÃ©es vectorielle | Gratuit |
| Gradio | 5.25.1 | Interface web | Gratuit |
| LangChain Chroma | 0.2.3 | IntÃ©gration Chroma | Gratuit |
| PyPDF | 5.4.0 | Traitement de fichiers PDF | Gratuit |
| Python Dotenv | 1.1.0 | Gestion variables d'environnement | Gratuit |

## ğŸ’° CoÃ»t Total

**$0.00** ğŸ‰ - Aucun frais de API, tout s'exÃ©cute localement !

## ğŸ“ AmÃ©liorations Futures

- [ ] Support de multiples formats (DOCX, TXT, etc.)
- [ ] Historique conversationnel persistant
- [ ] Interface d'upload de fichiers
- [ ] Filtrage par mÃ©tadonnÃ©es
- [ ] Autres modÃ¨les Ollama (Llama2, Neural Chat, etc.)
- [ ] Mode batch pour traitement multiple


## ğŸ¤ Contribution

Les contributions sont bienvenues ! N'hÃ©sitez pas Ã  :
- Signaler des bugs
- Proposer des amÃ©liorations
- Soumettre des pull requests

## ğŸ“„ Licence

Voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

## ğŸ“§ Support

Pour toute question ou problÃ¨me :
1. Consultez la section [DÃ©pannage](#-dÃ©pannage)
2. VÃ©rifiez les issues GitHub existantes
3. CrÃ©ez une nouvelle issue si besoin

## ğŸ“ Ressources Utiles

- [Documentation LangChain](https://python.langchain.com/)
- [Documentation OpenAI](https://platform.openai.com/docs/)
- [Documentation Chroma](https://docs.trychroma.com/)
- [Documentation Gradio](https://www.gradio.app/docs/)
- [RAG - Retrieval-Augmented Generation](https://arxiv.org/abs/2005.11401)

---

**CrÃ©Ã© avec â¤ï¸ pour faciliter l'interaction avec vos documents**
